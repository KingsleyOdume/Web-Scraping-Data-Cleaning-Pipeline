# ğŸŒ Web Scraping & Data Cleaning Pipeline

## Project Overview
This project demonstrates how to **scrape messy data from the web, clean it with Pandas, and store it into an SQL database** for dashboards & analysis.  
It automates the data pipeline â€” saving **80% of manual collection effort**.

---

## ğŸš€ Tech Stack
- **Python** â€“ scripting & automation
- **BeautifulSoup** â€“ web scraping
- **Pandas** â€“ data wrangling & cleaning
- **SQLite/MySQL** â€“ structured storage
- **Streamlit** â€“ interactive dashboard

---

## ğŸ› ï¸ Features
- ğŸŒ Automated web scraping
- ğŸ§¹ Data cleaning (missing values, duplicates, price formatting)
- ğŸ“‚ Save structured datasets into SQL
- ğŸ“Š Interactive Streamlit dashboard
- âš¡ Cuts down 80% manual effort

---

## ğŸ“¦ Installation

git clone https://github.com/KingsleyOdume/web_scraping_pipeline.git
cd web_scraping_pipeline
pip install -r requirements.txt

â–¶ï¸ Run the App
streamlit run app.py

Then open: http://localhost:8501

ğŸ“Š Example Workflow
Scrape product prices from a sample website
Clean & structure the dataset
Save into SQLite database
Load structured dataset for analysis & dashboards

ğŸ“Œ Why This Project Matters
Recruiters want to see real-world data skills:
âœ… Automating collection with Python
âœ… Cleaning messy datasets with Pandas
âœ… Structuring into SQL for analysis
This project demonstrates end-to-end data pipeline skills â€” essential for Data Analysts & Data Engineers.

ğŸ”— GitHub
View Code on GitHub
View Live Demo on Streamlit
Step-by-Step on My Portfolio
