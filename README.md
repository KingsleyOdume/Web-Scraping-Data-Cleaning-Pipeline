# 🌐 Web Scraping & Data Cleaning Pipeline

## Project Overview
This project demonstrates how to **scrape messy data from the web, clean it with Pandas, and store it into an SQL database** for dashboards & analysis.  
It automates the data pipeline — saving **80% of manual collection effort**.

---

## 🚀 Tech Stack
- **Python** – scripting & automation
- **BeautifulSoup** – web scraping
- **Pandas** – data wrangling & cleaning
- **SQLite/MySQL** – structured storage
- **Streamlit** – interactive dashboard

---

## 🛠️ Features
- 🌐 Automated web scraping
- 🧹 Data cleaning (missing values, duplicates, price formatting)
- 📂 Save structured datasets into SQL
- 📊 Interactive Streamlit dashboard
- ⚡ Cuts down 80% manual effort

---

## 📦 Installation

git clone https://github.com/KingsleyOdume/web_scraping_pipeline.git
cd web_scraping_pipeline
pip install -r requirements.txt

▶️ Run the App
streamlit run app.py

Then open: http://localhost:8501

📊 Example Workflow
Scrape product prices from a sample website
Clean & structure the dataset
Save into SQLite database
Load structured dataset for analysis & dashboards

📌 Why This Project Matters
Recruiters want to see real-world data skills:
✅ Automating collection with Python
✅ Cleaning messy datasets with Pandas
✅ Structuring into SQL for analysis
This project demonstrates end-to-end data pipeline skills — essential for Data Analysts & Data Engineers.

🔗 GitHub
View Code on GitHub
View Live Demo on Streamlit
Step-by-Step on My Portfolio
